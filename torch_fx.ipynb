{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**FX is a toolkit for developers to use to transform nn.Module instances. FX consists of three main components: a symbolic tracer, an intermediate representation, and Python code generation. A demonstration of these components in action:**"
      ],
      "metadata": {
        "id": "LYR-x2vKoRiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "class MyModule(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.param = torch.nn.Parameter(torch.rand(3, 4))\n",
        "        self.linear = torch.nn.Linear(4, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x + self.param).clamp(min=0.0, max=1.0)\n",
        "\n",
        "module = MyModule()\n",
        "\n",
        "from torch.fx import symbolic_trace\n",
        "symbolic_traced : torch.fx.GraphModule = symbolic_trace(module)\n",
        "\n",
        "print(symbolic_traced.graph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nl-QJbnAoPyG",
        "outputId": "a97d91ef-01fd-4acc-9b4e-0f590bd82923"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "graph():\n",
            "    %x : [num_users=1] = placeholder[target=x]\n",
            "    %param : [num_users=1] = get_attr[target=param]\n",
            "    %add : [num_users=1] = call_function[target=operator.add](args = (%x, %param), kwargs = {})\n",
            "    %linear : [num_users=1] = call_module[target=linear](args = (%add,), kwargs = {})\n",
            "    %clamp : [num_users=1] = call_method[target=clamp](args = (%linear,), kwargs = {min: 0.0, max: 1.0})\n",
            "    return clamp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(symbolic_traced.code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bj2pwnwQoH2k",
        "outputId": "b4981e1a-cfed-41e8-f4f1-fd1b827e4d1b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "def forward(self, x):\n",
            "    param = self.param\n",
            "    add = x + param;  x = param = None\n",
            "    linear = self.linear(add);  add = None\n",
            "    clamp = linear.clamp(min = 0.0, max = 1.0);  linear = None\n",
            "    return clamp\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Writing Transformations**"
      ],
      "metadata": {
        "id": "vLC0i4Lrok2Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build a New Graph**\n",
        "\n"
      ],
      "metadata": {
        "id": "3xFbWpINt2BP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.fx\n",
        "\n",
        "def transform(m: torch.nn.Module,\n",
        "              tracer_class: type = torch.fx.Tracer) -> torch.nn.Module:\n",
        "    graph: torch.fx.Graph = tracer_class().trace(m)\n",
        "\n",
        "    for node in graph.nodes:\n",
        "        if node.op == 'call_module' and 'linear' in node.target:\n",
        "            with graph.inserting_before(node):\n",
        "                relu_node = graph.create_node('call_function', torch.relu, args=(node.args[0],))\n",
        "\n",
        "            node.args = (relu_node,)\n",
        "\n",
        "    return torch.fx.GraphModule(m, graph)"
      ],
      "metadata": {
        "id": "VioYKEkKokXX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modify the Existing Graph in Place**"
      ],
      "metadata": {
        "id": "vfwGsgeguEVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.fx\n",
        "\n",
        "def transform(m: torch.nn.Module) -> torch.nn.Module:\n",
        "    gm: torch.fx.GraphModule = torch.fx.symbolic_trace(m)\n",
        "\n",
        "    for node in gm.graph.nodes:\n",
        "        if node.op == 'call_module' and 'linear' in node.target:\n",
        "            with gm.graph.inserting_after(node):\n",
        "                pass\n",
        "\n",
        "    gm.recompile()\n",
        "    return gm"
      ],
      "metadata": {
        "id": "PjpQKxherbbK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GRAPH**"
      ],
      "metadata": {
        "id": "PQ0OH88Asr1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.fx\n",
        "\n",
        "class MyModule(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.param = torch.nn.Parameter(torch.rand(3, 4))\n",
        "        self.linear = torch.nn.Linear(4, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.topk(torch.sum(\n",
        "            self.linear(x + self.linear.weight).relu(), dim=-1), 3)\n",
        "\n",
        "m = MyModule()\n",
        "gm = torch.fx.symbolic_trace(m)\n",
        "\n",
        "gm.graph.print_tabular()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ualt7DpSstuv",
        "outputId": "0abc41c0-3deb-4b42-ba3c-c9c35ae7131e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "opcode         name           target                                                   args                kwargs\n",
            "-------------  -------------  -------------------------------------------------------  ------------------  -----------\n",
            "placeholder    x              x                                                        ()                  {}\n",
            "get_attr       linear_weight  linear.weight                                            ()                  {}\n",
            "call_function  add            <built-in function add>                                  (x, linear_weight)  {}\n",
            "call_module    linear         linear                                                   (add,)              {}\n",
            "call_method    relu           relu                                                     (linear,)           {}\n",
            "call_function  sum_1          <built-in method sum of type object at 0x7cdddfe647e0>   (relu,)             {'dim': -1}\n",
            "call_function  topk           <built-in method topk of type object at 0x7cdddfe647e0>  (sum_1, 3)          {}\n",
            "output         output         output                                                   (topk,)             {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modifying the graph**"
      ],
      "metadata": {
        "id": "ullUSDqAtmi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for node in gm.graph.nodes:\n",
        "    if node.op == 'call_module' and node.target == 'linear':\n",
        "        with gm.graph.inserting_before(node):\n",
        "            const_node = gm.graph.create_node('call_function', torch.add, args=(node.args[0], torch.tensor(1.0)))\n",
        "        node.args = (const_node,)\n",
        "\n",
        "gm.recompile()\n",
        "gm.graph.print_tabular()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBdLgrQRtpoM",
        "outputId": "76f05b91-abec-4f7a-add3-8acd9202981a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "opcode         name           target                                                   args                kwargs\n",
            "-------------  -------------  -------------------------------------------------------  ------------------  -----------\n",
            "placeholder    x              x                                                        ()                  {}\n",
            "get_attr       linear_weight  linear.weight                                            ()                  {}\n",
            "call_function  add            <built-in function add>                                  (x, linear_weight)  {}\n",
            "call_function  add_1          <built-in method add of type object at 0x7cdddfe647e0>   (add, tensor(1.))   {}\n",
            "call_module    linear         linear                                                   (add_1,)            {}\n",
            "call_method    relu           relu                                                     (linear,)           {}\n",
            "call_function  sum_1          <built-in method sum of type object at 0x7cdddfe647e0>   (relu,)             {'dim': -1}\n",
            "call_function  topk           <built-in method topk of type object at 0x7cdddfe647e0>  (sum_1, 3)          {}\n",
            "output         output         output                                                   (topk,)             {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Direct Graph Manipulation**"
      ],
      "metadata": {
        "id": "UDnMaGOKvE3s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example: Replacing torch.add with torch.mul**\n",
        "\n",
        "* sample module M with a forward method that calls torch.add().\n",
        "\n",
        "* The transform() function traces the module, iterates over the graph nodes, and replaces any call to torch.add() with torch.mul().\n",
        "\n",
        "*   After transformation, running the modified module will multiply instead of adding the inputs.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aT5eG3a_vbiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.fx as fx\n",
        "\n",
        "class M(torch.nn.Module):\n",
        "    def forward(self, x, y):\n",
        "        return torch.add(x, y)\n",
        "\n",
        "def transform(m: torch.nn.Module, tracer_class: type = fx.Tracer) -> torch.nn.Module:\n",
        "    graph: fx.Graph = tracer_class().trace(m)\n",
        "\n",
        "    for node in graph.nodes:\n",
        "        if node.op == 'call_function' and node.target == torch.add:\n",
        "            node.target = torch.mul\n",
        "\n",
        "    graph.lint()\n",
        "    return fx.GraphModule(m, graph)\n",
        "\n",
        "module = M()\n",
        "transformed_module = transform(module)\n",
        "\n",
        "x = torch.tensor([1, 2, 3])\n",
        "y = torch.tensor([4, 5, 6])\n",
        "\n",
        "output = transformed_module(x, y)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2glkUq4vLhq",
        "outputId": "f013b6f2-8fdd-4b51-a795-6df75b8076be"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 4, 10, 18])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Subgraph Rewriting With replace_pattern()**\n",
        "\n",
        "*   Define a ConvBNPattern module with a Conv2d followed by a BatchNorm2d.\n",
        "\n",
        "*   Define ConvBNFused, where the batch normalization is fused with the convolution.\n",
        "*   The replace_pattern() API finds instances of the Conv2d -> BatchNorm2d pattern and replaces them with the fused version.\n",
        "\n"
      ],
      "metadata": {
        "id": "IFn6qgn_v-Fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.fx as fx\n",
        "\n",
        "class ConvBNPattern(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(3, 16, 3)\n",
        "        self.bn = nn.BatchNorm2d(16)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.bn(self.conv(x))\n",
        "\n",
        "class ConvBNFused(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(3, 16, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "model = ConvBNPattern()\n",
        "traced = fx.symbolic_trace(model)\n",
        "\n",
        "fx.subgraph_rewriter.replace_pattern(traced, ConvBNPattern(), ConvBNFused())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8XRt79XwVYs",
        "outputId": "fcc18ea4-8ef1-4280-9260-4fc9a742eb84"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Match(anchor=bn, nodes_map={bn: bn, conv: conv, x: x})]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Proxy/Retracing**\n",
        "\n",
        "*   relu_decomposition(x): Replaces F.relu(x) with the element-wise operation (x > 0) * x.\n",
        "*   decompose(model): Iterates through the traced graph of the model, applying the relu_decomposition transformation to any F.\n",
        "*   Proxy objects: Used to wrap nodes when tracing. These Proxies capture the operations performed on them, which helps to build the new computation graph automatically.   \n",
        "\n"
      ],
      "metadata": {
        "id": "qMDAulhVyBO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.fx as fx\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def relu_decomposition(x):\n",
        "    return (x > 0) * x\n",
        "\n",
        "decomposition_rules = {F.relu: relu_decomposition}\n",
        "\n",
        "def decompose(model: torch.nn.Module, tracer_class: type = fx.Tracer) -> torch.nn.Module:\n",
        "    graph: fx.Graph = tracer_class().trace(model)\n",
        "    new_graph = fx.Graph()\n",
        "    env = {}\n",
        "    tracer = torch.fx.proxy.GraphAppendingTracer(new_graph)\n",
        "\n",
        "    for node in graph.nodes:\n",
        "        if node.op == 'call_function' and node.target in decomposition_rules:\n",
        "            proxy_args = [fx.Proxy(env[x.name], tracer) if isinstance(x, fx.Node) else x for x in node.args]\n",
        "            output_proxy = decomposition_rules[node.target](*proxy_args)\n",
        "            new_node = output_proxy.node\n",
        "            env[node.name] = new_node\n",
        "        else:\n",
        "            new_node = new_graph.node_copy(node, lambda x: env[x.name])\n",
        "            env[node.name] = new_node\n",
        "\n",
        "    return fx.GraphModule(model, new_graph)\n",
        "\n",
        "class M(torch.nn.Module):\n",
        "    def forward(self, x):\n",
        "        return F.relu(x)\n",
        "\n",
        "model = M()\n",
        "transformed_model = decompose(model)\n",
        "\n",
        "x = torch.tensor([-1.0, 0.0, 1.0])\n",
        "\n",
        "output = transformed_model(x)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYRqFaL5yFRy",
        "outputId": "ecda56a8-96cb-4ea5-dd07-0200c6dd3b07"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0., 0., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Custom Transformer**"
      ],
      "metadata": {
        "id": "_q6Knw5_2_1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.fx as fx\n",
        "\n",
        "class CustomTransformer(fx.Transformer):\n",
        "    def call_function(self, target, args, kwargs):\n",
        "        if target == torch.add:\n",
        "            return self.call_function(torch.mul, args, kwargs)\n",
        "        return super().call_function(target, args, kwargs)\n",
        "\n",
        "class M(torch.nn.Module):\n",
        "    def forward(self, x, y):\n",
        "        return torch.add(x, y)\n",
        "\n",
        "model = M()\n",
        "tracer = fx.Tracer()\n",
        "graph = tracer.trace(model)\n",
        "gm = fx.GraphModule(model, graph)\n",
        "transformed_gm = CustomTransformer(gm).transform()\n",
        "\n",
        "x, y = torch.tensor(2.0), torch.tensor(3.0)\n",
        "print(transformed_gm(x, y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjLTcTjx26O8",
        "outputId": "c01f9199-f9e1-49ae-ce36-992461ab6122"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(6.)\n"
          ]
        }
      ]
    }
  ]
}